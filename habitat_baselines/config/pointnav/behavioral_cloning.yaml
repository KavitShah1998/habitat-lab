BASE_TASK_CONFIG_PATH: "configs/tasks/pointnav_gibson.yaml"
TENSORBOARD_DIR:    '/nethome/nyokoyama3/n/cont_ctrl_results/junk/tb'
VIDEO_DIR:          '/nethome/nyokoyama3/n/cont_ctrl_results/junk/video_dir'
EVAL_CKPT_PATH_DIR: '/nethome/nyokoyama3/n/cont_ctrl_results/junk/checkpoints'
CHECKPOINT_FOLDER:  '/coc/pskynet3/nyokoyama3/learnbycheat/8_1000/checkpoints'
TXT_DIR:            '/nethome/nyokoyama3/n/cont_ctrl_results/junk/txts'
TRAINER_NAME: "ddppo"
ENV_NAME: "NavRLEnv"
SIMULATOR_GPU_ID: 0
TORCH_GPU_ID: 0
VIDEO_OPTION: []
TEST_EPISODE_COUNT: -1
SENSORS: ["DEPTH_SENSOR"]
NUM_UPDATES: 10000000
LOG_INTERVAL: 10
CHECKPOINT_INTERVAL: 250

# Things that wandb should log:
BC:
  NUM_PROCESSES: 72
  BATCH_LENGTH: 8
  LAST_TEACHER_BATCH: 1000
  NUM_ITERATIONS: 50000
  SL_LR: 2.5e-4 # learning rate for supervised learning
  DEQUE_LENGTH: 50
  SGD: False 
  SAVE_ITERATIONS: 50000

RL:
  SUCCESS_REWARD: 2.5
  STEP_REWARD_DECAY: 80000000 # At how many frames will it decay all the way to 0 
  PPO:
    # ppo params
    clip_param: 0.2
    ppo_epoch: 2
    num_mini_batch: 2
    value_loss_coef: 0.5
    entropy_coef: 0.01
    lr: 2.5e-4
    eps: 1e-5
    max_grad_norm: 0.2
    num_steps: 128
    use_gae: True
    gamma: 0.99
    tau: 0.95
    use_linear_clip_decay: False
    use_linear_lr_decay: False
    reward_window_size: 50

    use_normalized_advantage: False

    hidden_size: 512

  DDPPO:
    sync_frac: 0.6
    # The PyTorch distributed backend to use
    distrib_backend: GLOO
    # Visual encoder backbone
    pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
    # Initialize with pretrained weights
    pretrained: False
    # Initialize just the visual encoder backbone with pretrained weights
    pretrained_encoder: False
    # Whether or not the visual encoder backbone will be trained.
    train_encoder: True
    # Whether or not to reset the critic linear layer
    reset_critic: True

    # Model parameters
    backbone: resnet50
    rnn_type: LSTM
    num_recurrent_layers: 2